## Work done so far
- Implemented Genetic Algorithm to optimize ANNs and CNNs (for a classification task)
- Hyperparameter tuning of CNN using Genetic Algorithm
- L1 pruning of lightweight models like TinyBERT and ALBERT

## Future Work
- [x] Build a small-scale GPT from scratch to understand the transformer architecture and the concept of self-attention
- [x] Explore various LLM compression techniques like pruning and knowledge distillation
- [ ] Look into other pruning strategies (e.g. one-shot pruning)
- [ ] Figure out how to perform fine-tuning (SFT, PEFT) of LLMs in a [federated](https://developer.nvidia.com/blog/turning-machine-learning-to-federated-learning-in-minutes-with-nvidia-flare-2-4/) setting 
- [ ] [Swarm Learning](https://www.nature.com/articles/s41586-021-03583-3) for fine-tuning
